{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/subornaa/Data-Analytics-Tutorials/blob/main/Lasso_and_Ridge_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "OMbBxBKDh1bd"
      },
      "id": "OMbBxBKDh1bd"
    },
    {
      "cell_type": "markdown",
      "id": "0f03f594",
      "metadata": {
        "id": "0f03f594"
      },
      "source": [
        "# Regularization Techniques: Lasso and Ridge Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47879c8e",
      "metadata": {
        "id": "47879c8e"
      },
      "source": [
        "# Introduction and Dataset\n",
        "\n",
        "## Background\n",
        "\n",
        "This tutorial will explore Lasso and Ridge regression methods to model different response variables that are commonly modeled in forestry. These include quadratic mean diameter (QMD), aboveground biomass (AGB), and basal area (BA). The tutorial will employ a suite of input features (i.e., predictor variables) used to estimate the response variables.\n",
        "\n",
        "## Tutorial goals\n",
        "\n",
        "**Goal 1: Develope ridge and lasso regression models for QMD, AGB, and BA using LiDAR and multispectral predictor variables**\n",
        "\n",
        "**Goal 2: Compare ridge and lasso models for each response variable and choose the best model for each**\n",
        "\n",
        "**Goal 3: Apply the best performing model for each response variable across the entire PRF**\n",
        "\n",
        "-----\n",
        "\n",
        "## Data\n",
        "\n",
        "Please refer to the README on the main GitHub page for a detailed description of each file.\n",
        "\n",
        "\n",
        "## Packages\n",
        "\n",
        "- GeoPandas\n",
        "- rioxarray\n",
        "- spyndex"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kMT_CFPFDfwo",
      "metadata": {
        "id": "kMT_CFPFDfwo"
      },
      "source": [
        "# Install and load packages\n",
        "\n",
        "**Uncomment the cell below to install required packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZbKJznL_Ens1",
      "metadata": {
        "id": "ZbKJznL_Ens1"
      },
      "outputs": [],
      "source": [
        "!pip install -q pandas==2.2.2\n",
        "!pip install -q geopandas==1.0.1\n",
        "!pip install -q matplotlib==3.10.1\n",
        "!pip install -q rioxarray==0.19.0\n",
        "!pip install -q spyndex==0.5.0\n",
        "!pip install -q pyarrow==19.0.0\n",
        "!pip install -q laspy[lazrs]==2.5.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XlUJu_obDh7n",
      "metadata": {
        "id": "XlUJu_obDh7n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import rioxarray as rio\n",
        "import spyndex\n",
        "import laspy\n",
        "from spyndex import indices\n",
        "from math import sqrt, pi\n",
        "import matplotlib.pyplot as plt\n",
        "from rasterio.plot import show\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UMkjANynDdxi",
      "metadata": {
        "id": "UMkjANynDdxi"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zK7hDjx_De8D",
      "metadata": {
        "id": "zK7hDjx_De8D"
      },
      "outputs": [],
      "source": [
        "# Download the data if it does not yet exist\n",
        "if not os.path.exists(\"data\"):\n",
        "  !gdown 1UDKAdXW0h6JSf7k31PZ-srrQ3487l9e2\n",
        "  !unzip prf_data.zip -d data/\n",
        "  os.remove(\"prf_data.zip\")\n",
        "else:\n",
        "  print(\"Data has already been downloaded.\")\n",
        "\n",
        "os.listdir(\"data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2ce5425",
      "metadata": {
        "id": "f2ce5425"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "Before we can begin with ridge and lasso regression, we must first preprocess the data so it is analysis ready. The following code blocks will prepare both the response variables (QMD, AGB, BA) in addition to predictor variables (99th height percentile and spectral indices)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bdffcd9",
      "metadata": {
        "id": "3bdffcd9"
      },
      "outputs": [],
      "source": [
        "trees_df = gpd.read_file(r'data/trees.csv')\n",
        "plots_gdf = gpd.read_file(r'data/plots.gpkg').rename(columns={\"Plot\": \"PlotName\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block of code ensures that the `biomass`, `height`, `baha` and `DBH` columns in trees_df are numeric"
      ],
      "metadata": {
        "id": "-Cehjbqga51b"
      },
      "id": "-Cehjbqga51b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52e58464",
      "metadata": {
        "id": "52e58464"
      },
      "outputs": [],
      "source": [
        "cols_to_convert = ['biomass', 'height', 'baha', 'DBH']\n",
        "for col in cols_to_convert:\n",
        "    trees_df[col] = pd.to_numeric(trees_df[col])\n",
        "\n",
        "trees_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets check the range of various tree attributes, they seem good!"
      ],
      "metadata": {
        "id": "XNboCfc_bTe5"
      },
      "id": "XNboCfc_bTe5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "addc4f67",
      "metadata": {
        "id": "addc4f67"
      },
      "outputs": [],
      "source": [
        "trees_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73b4b3e2",
      "metadata": {
        "id": "73b4b3e2"
      },
      "source": [
        "## Response Variables\n",
        "\n",
        "Just as a refresher, this is the variable that is being measured, observed, or is the focus of the study. Its expcted to change in relation with other variables. Below is the exploration of the response variables we will be looking at"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quadratic Mean Diameter\n",
        "\n",
        "Quadratic Mean Diameter (QMD) is a common stand level attribute that is modeled in forestry. QMD is often prefered over the arithmetic mean in forestry because it gives greater weight to larger trees. This is relevant for several reasons, primarily though because the wood from larger trees is more valuable.\n",
        "\n",
        "QMD also is relevant for understanding forest ecology among other applications."
      ],
      "metadata": {
        "id": "DoLhxxZMkL6B"
      },
      "id": "DoLhxxZMkL6B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6854f9f",
      "metadata": {
        "id": "d6854f9f"
      },
      "outputs": [],
      "source": [
        "# Calculate the Quadratic Mean Diameter (QMD)\n",
        "qmd_df = (\n",
        "    trees_df\n",
        "    .groupby('PlotName')\n",
        "    .agg(\n",
        "        n_trees=('DBH', 'count'),\n",
        "        sum_squares=('DBH', lambda x: (x**2).sum())\n",
        "    )\n",
        "    .assign(qmd=lambda df: (df['sum_squares'] / df['n_trees']).apply(sqrt))\n",
        "    .reset_index()[['PlotName', 'qmd']]\n",
        ")\n",
        "\n",
        "print(qmd_df.describe())\n",
        "\n",
        "# Join with plots GeoDataFrame\n",
        "plots_gdf = plots_gdf.merge(qmd_df, on='PlotName', how='left')\n",
        "\n",
        "ax = plots_gdf['qmd'].hist(edgecolor='black', color='green')\n",
        "ax.set_xlabel('QMD (cm)')\n",
        "ax.set_ylabel('Number of Plots')\n",
        "ax.set_title('Distribution of Quadratic Mean Diameter (QMD)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1c363c3",
      "metadata": {
        "id": "f1c363c3"
      },
      "source": [
        "### Aboveground Biomass (AGB)\n",
        "\n",
        "Forest aboveground biomass (AGB) is another very common stand attribute to model. Biomass is defined as the living organic materials comprising trees including wood, bark, branches, foliage, etc. AGB is modeled for many different reasons. One relevant application of AGB modelling is for forest carbon projects, since forest aboveground carbon is typically estimated to be ~50% of AGB.\n",
        "\n",
        "We can calculate plot-level AGB by summing the AGB of all trees in a plot, and then dividing that by the plot area. This is performed in the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1be5dfa",
      "metadata": {
        "id": "c1be5dfa"
      },
      "outputs": [],
      "source": [
        "# Note that each plot has a radius of 14.1m (625m^2)\n",
        "# We need to convert to hectares, since this is the most common areal unit in forestry.\n",
        "# There are 10000 m^2 in a hectare, so we divide by 10000.\n",
        "\n",
        "plot_area_m2 = 625\n",
        "\n",
        "plot_area_ha = plot_area_m2 / 10000\n",
        "\n",
        "print(f\"Area of each plot in hectares: {plot_area_ha} ha\")\n",
        "\n",
        "# Convert tree-level biomass from Kg/ha to Kg, and then to Mg (tonnes).\n",
        "trees_df['biomass_kg'] = trees_df['biomass'] * plot_area_ha\n",
        "trees_df['biomass_Mg'] = trees_df['biomass_kg'] / 1000\n",
        "\n",
        "biomass_df = (trees_df.groupby('PlotName').\n",
        "                    agg(biomass_Mg_total=('biomass_Mg', 'sum')).\n",
        "                    assign(biomass_Mg_ha=lambda x: x['biomass_Mg_total'] / plot_area_ha))\n",
        "\n",
        "# Summarize biomass\n",
        "print(biomass_df.describe())\n",
        "\n",
        "# Join with plots GeoDataFrame\n",
        "plots_gdf = plots_gdf.merge(biomass_df, on='PlotName', how='left')\n",
        "\n",
        "ax = biomass_df['biomass_Mg_total'].hist(edgecolor='black', color='green')\n",
        "ax.set_xlabel('AGB (Mg/ha)')\n",
        "ax.set_ylabel('Number of Plots')\n",
        "ax.set_title('Distribution of Aboveground Biomass')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63a5c9db",
      "metadata": {
        "id": "63a5c9db"
      },
      "source": [
        "### Basal Area\n",
        "\n",
        "Basal Area represents the cross-sectional area of all trees per unit land area, It reflects how crowded or sparse a forest is, which is important for understanding growth conditions, competition, and habitat quality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a04506ab",
      "metadata": {
        "id": "a04506ab"
      },
      "outputs": [],
      "source": [
        "def get_ba(dbh):\n",
        "    return ((dbh / 2) ** 2) * pi\n",
        "\n",
        "ba_df = (trees_df\n",
        "            .assign(ba_cm2=lambda x: get_ba(x['DBH']))\n",
        "            .assign(ba_m2=lambda x: x['ba_cm2'] / 10000)\n",
        "            .groupby('PlotName')\n",
        "            .agg(total_ba_m2_ha=('ba_m2', 'sum'))\n",
        "            .assign(ba_m2_ha=lambda x: x['total_ba_m2_ha'] / plot_area_ha)\n",
        "            .reset_index())\n",
        "\n",
        "ba_df.describe()\n",
        "\n",
        "# Join with plots GeoDataFrame\n",
        "plots_gdf = plots_gdf.merge(ba_df, on='PlotName', how='left')\n",
        "\n",
        "ax = plots_gdf['ba_m2_ha'].hist(edgecolor='black', color='green')\n",
        "ax.set_xlabel('Basal Area (m2/ha)')\n",
        "ax.set_ylabel('Number of Plots')\n",
        "ax.set_title('Distribution of Basal Area (BA)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "905b3b1f",
      "metadata": {
        "id": "905b3b1f"
      },
      "source": [
        "## Predictor Variables\n",
        "\n",
        "This is the variable that is manipulated, controlled, or measured to see if it has an effect on the response variable. In our experiment, we would be trying to predict special indecies and ALS metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Airborne Laser Scanning (ALS) derived metrics.\n",
        "\n",
        "We load the ALS metrics (ALS is a type of LiDAR) as an xarray dataset. xarray is similar to numpy arrays, but with added attributes and functionality. For example, xarrays can contain spatial coordinate reference systems (CRS)."
      ],
      "metadata": {
        "id": "pHZp9PYDnH8t"
      },
      "id": "pHZp9PYDnH8t"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets first read the `als_metrics`"
      ],
      "metadata": {
        "id": "va-oELSSsli3"
      },
      "id": "va-oELSSsli3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ced2e02e",
      "metadata": {
        "id": "ced2e02e"
      },
      "outputs": [],
      "source": [
        "als_metrics = rio.open_rasterio(r'data/als_metrics.tif')\n",
        "als_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure that raster and plot coordinates are in the same CRS."
      ],
      "metadata": {
        "id": "6v6W4jsIYD3b"
      },
      "id": "6v6W4jsIYD3b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "359f6e6b",
      "metadata": {
        "id": "359f6e6b"
      },
      "outputs": [],
      "source": [
        "assert plots_gdf.crs == als_metrics.rio.crs, \"CRS mismatch between plots and raster data.\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert ALS metric names from a tuple to a list for later use."
      ],
      "metadata": {
        "id": "s1JsiE_EwRar"
      },
      "id": "s1JsiE_EwRar"
    },
    {
      "cell_type": "code",
      "source": [
        "als_metrics_nms = list(als_metrics.long_name)"
      ],
      "metadata": {
        "id": "F9N0K0aHlXLp"
      },
      "id": "F9N0K0aHlXLp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1 - Next, we create a list of plot coordinate tuples by iterating through each ALS metric (by index) and extracting the value at each plot location. Fill in the code below.**"
      ],
      "metadata": {
        "id": "UPNUrvm1wmv7"
      },
      "id": "UPNUrvm1wmv7"
    },
    {
      "cell_type": "code",
      "source": [
        "plot_coords = [(geom.x, geom.y) for geom in plots_gdf.geometry]\n",
        "\n",
        "for i, metric in enumerate(als_metrics_nms):\n",
        "\n",
        "    #Uncomment the line below to see all the difference metrics\n",
        "    #print(f\"Extracting metric: {metric}\")\n",
        "\n",
        "    metric_ras_i = ...[i]\n",
        "    plots_gdf[metric] = [float(metric_ras_i.sel(x=c[0], y=c[1], method=\"nearest\").values) for c in plot_coords]"
      ],
      "metadata": {
        "id": "0c8At9wxt8ow"
      },
      "id": "0c8At9wxt8ow",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09a33811",
      "metadata": {
        "id": "09a33811",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Solution\n",
        "plot_coords = [(geom.x, geom.y) for geom in plots_gdf.geometry]\n",
        "\n",
        "for i, metric in enumerate(als_metrics_nms):\n",
        "\n",
        "    #Uncomment the line below to see all the difference metrics\n",
        "    #print(f\"Extracting metric: {metric}\")\n",
        "\n",
        "    metric_ras_i = als_metrics[i]\n",
        "    plots_gdf[metric] = [float(metric_ras_i.sel(x=c[0], y=c[1], method=\"nearest\").values) for c in plot_coords]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets view the distribution of the 99th height percentile, it looks normal."
      ],
      "metadata": {
        "id": "Mj383Ihhw1Oe"
      },
      "id": "Mj383Ihhw1Oe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "648af048",
      "metadata": {
        "id": "648af048"
      },
      "outputs": [],
      "source": [
        "ax = plots_gdf['p99'].hist(edgecolor='black', color='blue')\n",
        "ax.set_xlabel('99th Height Percentile (m)')\n",
        "ax.set_ylabel('Number of Plots')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets extract the spectral indices to use a predictor variables"
      ],
      "metadata": {
        "id": "q-5-jTtj0I6Z"
      },
      "id": "q-5-jTtj0I6Z"
    },
    {
      "cell_type": "markdown",
      "id": "e71a8bde",
      "metadata": {
        "id": "e71a8bde"
      },
      "source": [
        "### Sentinel-2 Spectral Indices\n",
        "\n",
        "While we can write code to calculate spectral indices, this can become time consuming once we start dealing with many different indices. Moreover, we can make mistakes in our code. As a suitable alternative, the `spyndex` Python package offers a standardized, simpler method for calculating many spectral indices at once.\n",
        "\n",
        "Read the spyndex documentation here: [https://spyndex.readthedocs.io/en/stable/](https://spyndex.readthedocs.io/en/stable/)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " First we load the Sentinel-2 imagery for 2018 (year the plots were sampled)."
      ],
      "metadata": {
        "id": "W_xf7fTLxUWU"
      },
      "id": "W_xf7fTLxUWU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "718f2e7b",
      "metadata": {
        "id": "718f2e7b"
      },
      "outputs": [],
      "source": [
        "s2 = rio.open_rasterio(r'data/petawawa_s2_2018.tif')\n",
        "\n",
        "assert plots_gdf.crs == s2.rio.crs, \"CRS mismatch between plots and raster data.\"\n",
        "\n",
        "# Consult the documentation for the spectral bands:\n",
        "# https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR_HARMONIZED\n",
        "s2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check range of reflectance for each band."
      ],
      "metadata": {
        "id": "re4hW6CxxKMG"
      },
      "id": "re4hW6CxxKMG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4472430d",
      "metadata": {
        "id": "4472430d"
      },
      "outputs": [],
      "source": [
        "print(\"Min reflectance in S2 data:\", np.nanmin(s2.values))\n",
        "print(\"Max reflectance in S2 data:\", np.nanmax(s2.values))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0f8378a",
      "metadata": {
        "id": "b0f8378a"
      },
      "source": [
        "**Consult this table for more details about band abbreviations used for spectral index calculation:**\n",
        "\n",
        "[https://github.com/awesome-spectral-indices/awesome-spectral-indices?tab=readme-ov-file#expressions](https://github.com/awesome-spectral-indices/awesome-spectral-indices?tab=readme-ov-file#expressions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1912cb3",
      "metadata": {
        "id": "a1912cb3"
      },
      "outputs": [],
      "source": [
        "print(\"Sentinel-2 band names order:\", s2.long_name)\n",
        "print(\"Spyndex band abbreviations:\", spyndex.bands)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a list of spectral indices to calculate."
      ],
      "metadata": {
        "id": "zwYLKzWixoA3"
      },
      "id": "zwYLKzWixoA3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ab19aaa",
      "metadata": {
        "id": "4ab19aaa"
      },
      "outputs": [],
      "source": [
        "spec_index_ls = [\"NDVI\", \"NBR\", \"SAVI\", \"MSAVI\", \"DSI\", \"NDWI\", \"GLI\",  \"ND705\", \"NDREI\", \"IRECI\", \"TGI\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One nice thing about spyndex is that it links each spectral index with a publication describing it. This code lists all the publications for each index."
      ],
      "metadata": {
        "id": "GGFow5SGxtAf"
      },
      "id": "GGFow5SGxtAf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "415dda0e",
      "metadata": {
        "id": "415dda0e"
      },
      "outputs": [],
      "source": [
        "for si in spec_index_ls:\n",
        "    print(f\"{si}: {indices[si].reference}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code gets all the spectral indices."
      ],
      "metadata": {
        "id": "QKK5ASGF2NfU"
      },
      "id": "QKK5ASGF2NfU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ca84081",
      "metadata": {
        "id": "9ca84081"
      },
      "outputs": [],
      "source": [
        "spec_indeces = spyndex.computeIndex(\n",
        "    index = spec_index_ls,\n",
        "    params = {\n",
        "        \"A\": s2[0],\n",
        "        \"B\": s2[1],\n",
        "        \"G\": s2[2],\n",
        "        \"R\": s2[3],\n",
        "        \"RE1\": s2[4],\n",
        "        \"RE2\": s2[5],\n",
        "        \"RE3\": s2[6],\n",
        "        \"N\": s2[7],\n",
        "        \"N2\": s2[8],\n",
        "        \"WV\": s2[9],\n",
        "        \"S1\": s2[10],\n",
        "        \"S2\": s2[11],\n",
        "        \"L\": 1\n",
        "    }\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2 - Use the `spec_indeces` found before to extract the spectral indices into a dataframe. Fill in the code below.**"
      ],
      "metadata": {
        "id": "KgjUGSD22WMe"
      },
      "id": "KgjUGSD22WMe"
    },
    {
      "cell_type": "code",
      "source": [
        "for si_name in spec_index_ls:\n",
        "\n",
        "    #Uncomment this line below to see the code extracting\n",
        "    #print(f\"Extracting {si_name} values at plot coordinates...\")\n",
        "\n",
        "    si_raster = ...[spec_indeces.index == si_name]\n",
        "\n",
        "    plots_gdf[si_name] = [si_raster.sel(x=c[0], y=c[1], method=\"nearest\").values[0] for c in plot_coords]\n",
        "\n",
        "plots_gdf.head(5)"
      ],
      "metadata": {
        "id": "BU69huPn0O5C"
      },
      "id": "BU69huPn0O5C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cddd8d28",
      "metadata": {
        "id": "cddd8d28",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Solution\n",
        "for si_name in spec_index_ls:\n",
        "\n",
        "    #Uncomment this line below to see the code extracting\n",
        "    #print(f\"Extracting {si_name} values at plot coordinates...\")\n",
        "\n",
        "    si_raster = spec_indeces[spec_indeces.index == si_name]\n",
        "\n",
        "    plots_gdf[si_name] = [si_raster.sel(x=c[0], y=c[1], method=\"nearest\").values[0] for c in plot_coords]\n",
        "\n",
        "plots_gdf.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets view one of the spectral indices."
      ],
      "metadata": {
        "id": "SKbFdfos2tD3"
      },
      "id": "SKbFdfos2tD3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ad38050",
      "metadata": {
        "id": "8ad38050"
      },
      "outputs": [],
      "source": [
        "view_si_nm = \"NDVI\"\n",
        "view_si_raster = spec_indeces[spec_indeces.index == si_name]\n",
        "show(view_si_raster.values[0], cmap='viridis')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the geodataframe to regular dataframe allows for easier manipulation."
      ],
      "metadata": {
        "id": "JYTBInst21zy"
      },
      "id": "JYTBInst21zy"
    },
    {
      "cell_type": "code",
      "source": [
        "plots_df = pd.DataFrame(plots_gdf)\n",
        "plots_df.head()"
      ],
      "metadata": {
        "id": "RPK3eDtcl-Xz"
      },
      "id": "RPK3eDtcl-Xz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have gathered all the necessary information, we can finalize our dataset by creating lists of all predictor and response variables.  \n",
        "**Note:** In Python, two lists can be concatenated using the `+` operator.  \n",
        "Please keep in mind that the predictor variables are distributed across two DataFrames: `spec_index_ls` and `als_metrics_nms`.\n",
        "\n",
        "\n",
        "**Question 3 - fill in the code below.**"
      ],
      "metadata": {
        "id": "iHHdg20R7oPO"
      },
      "id": "iHHdg20R7oPO"
    },
    {
      "cell_type": "code",
      "source": [
        "predictor_vars = ... + ...\n",
        "print(\"Predictor variables:\", predictor_vars)\n",
        "\n",
        "response_vars = [\"biomass_Mg_ha\", \"ba_m2_ha\", \"qmd\"]\n",
        "print(\"Response variables:\", response_vars)"
      ],
      "metadata": {
        "id": "iXVmawWH06nD"
      },
      "id": "iXVmawWH06nD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68993613",
      "metadata": {
        "id": "68993613",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Solution\n",
        "predictor_vars = spec_index_ls + als_metrics_nms\n",
        "print(\"Predictor variables:\", predictor_vars)\n",
        "\n",
        "response_vars = [\"biomass_Mg_ha\", \"ba_m2_ha\", \"qmd\"]\n",
        "print(\"Response variables:\", response_vars)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is always good practice to ensure that there are no unexpected NaN values in the dataset.  \n",
        "To do this, remove any rows containing NaN values in the predictor or response variables using the `dropna()` function."
      ],
      "metadata": {
        "id": "WbJRKs85-OX0"
      },
      "id": "WbJRKs85-OX0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b959701",
      "metadata": {
        "id": "5b959701"
      },
      "outputs": [],
      "source": [
        "plots_df = plots_df.dropna(subset=response_vars + predictor_vars)\n",
        "plots_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's examine the correlation matrix of the predictor and response variables.  \n",
        "We primarily do this to identify any unusual or unexpected relationships in the data that may indicate issues or outliers."
      ],
      "metadata": {
        "id": "778d2BYW-on_"
      },
      "id": "778d2BYW-on_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7d49f87",
      "metadata": {
        "id": "a7d49f87"
      },
      "outputs": [],
      "source": [
        "corr_matrix = plots_df[response_vars + predictor_vars].corr()\n",
        "corr_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a quick look at our data.  \n",
        "While we cannot identify any clear trends from this variable alone, we can explore what insights might be gained using Lasso and Ridge regression techniques."
      ],
      "metadata": {
        "id": "MnUt0cVx_ctc"
      },
      "id": "MnUt0cVx_ctc"
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
        "\n",
        "# First plot: NDVI vs biomass\n",
        "plots_df.plot.scatter(x='NDVI', y='biomass_Mg_ha', ax=axes[0])\n",
        "axes[0].set_title('NDVI vs Biomass')\n",
        "\n",
        "# Second plot: p99 vs biomass\n",
        "plots_df.plot.scatter(x='p99', y='biomass_Mg_ha', ax=axes[1])\n",
        "axes[1].set_title('p99 vs Biomass')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cWufBW3KmKM0"
      },
      "id": "cWufBW3KmKM0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export plots with predictor variables for later use"
      ],
      "metadata": {
        "id": "fJJlpFTUj_Em"
      },
      "id": "fJJlpFTUj_Em"
    },
    {
      "cell_type": "code",
      "source": [
        "plots_df[['PlotName'] + predictor_vars].to_csv('data/predictors.csv', index=False)"
      ],
      "metadata": {
        "id": "p6yb4-mqlD2C"
      },
      "id": "p6yb4-mqlD2C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Goal 1: Develope ridge and lasso regression models for QMD, AGB, and BA using LiDAR and multispectral predictor variables"
      ],
      "metadata": {
        "id": "PIzlv2QZab7T"
      },
      "id": "PIzlv2QZab7T"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand the purpose of the required packages:\n",
        "\n",
        "- `train_test_split` is used to divide the dataset into training and testing sets. This helps us evaluate our model on \"unseen\" data, simulating how it would perform in real-world scenarios and reducing the risk of overfitting.\n",
        "\n",
        "- `Lasso` is a linear regression model with L1 regularization. It adds a penalty that shrinks less important feature coefficients to zero, effectively performing feature selection. This improves model interpretability and helps prevent overfitting.\n",
        "\n",
        "- `mean_squared_error` and `r2_score` are evaluation metrics.\n",
        "    - mean_squared_error measures the average squared difference between actual and predicted values.\n",
        "\n",
        "    - r2_score (coefficient of determination) indicates how well the model explains the variance in the target variable.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2vvOVKmhBVVd"
      },
      "id": "2vvOVKmhBVVd"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "i1EerCDVBQ3P"
      },
      "id": "i1EerCDVBQ3P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the setup is complete, we will define our target variable as `biomass_Mg_ha` and extract the predictor (`X`) and target (`y`) datasets accordingly.\n",
        "\n",
        "Next, we will split the data into training and testing sets, reserving the test set for final model evaluation on unseen data.\n",
        "\n",
        "**Question 1 - fill in the code below.**"
      ],
      "metadata": {
        "id": "Rhng90V2DvJ5"
      },
      "id": "Rhng90V2DvJ5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set target variable\n",
        "target_var = \"biomass_Mg_ha\"\n",
        "\n",
        "# Divide features and targets into separate DataFrames\n",
        "X = plots_gdf[...]\n",
        "y = plots_gdf[...]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, ..., y_test = ...(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "fSZTJVn17pM-"
      },
      "id": "fSZTJVn17pM-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbc5644a",
      "metadata": {
        "id": "fbc5644a",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Solution\n",
        "# Set target variable\n",
        "target_var = \"biomass_Mg_ha\"\n",
        "\n",
        "# Divide features and targets into separate DataFrames\n",
        "X = plots_gdf[predictor_vars]\n",
        "y = plots_gdf[target_var]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block of code isn't strictly necessary for every experiment, but it serves as a final check to ensure data quality. It verifies that the dataset dimensions are consistent and that there are no unwanted NaN values before training the model."
      ],
      "metadata": {
        "id": "w-AzsIvXEzNe"
      },
      "id": "w-AzsIvXEzNe"
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.concat([X_train, y_train], axis=1)\n",
        "train_df_clean = train_df.dropna()\n",
        "\n",
        "# Separate features and target again\n",
        "X_train = train_df_clean[predictor_vars]\n",
        "y_train = train_df_clean[target_var]"
      ],
      "metadata": {
        "id": "YRT_dYTGEu0z"
      },
      "id": "YRT_dYTGEu0z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can finally train the model!\n",
        "\n",
        "**Question 2 - fill in the code below.**"
      ],
      "metadata": {
        "id": "E9Y0XfGbFrNM"
      },
      "id": "E9Y0XfGbFrNM"
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a lasso regression model with initial alpha=0.1\n",
        "lasso = ...(alpha=0.99, max_iter=100000)\n",
        "lasso....(X_train, y_train)"
      ],
      "metadata": {
        "id": "q_iap9DQ8Dq7"
      },
      "id": "q_iap9DQ8Dq7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Solution\n",
        "# Train a lasso regression model with initial alpha=0.1\n",
        "lasso = Lasso(alpha=0.99, max_iter=100000)\n",
        "lasso.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "hRcjBAaYEwuc",
        "cellView": "form"
      },
      "id": "hRcjBAaYEwuc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we train the model, we can use the test set as a true test of how accruate the model is."
      ],
      "metadata": {
        "id": "vOtyJTmyFwmv"
      },
      "id": "vOtyJTmyFwmv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85c2fb78",
      "metadata": {
        "id": "85c2fb78"
      },
      "outputs": [],
      "source": [
        "test_df = pd.concat([X_test, y_test], axis=1)\n",
        "test_df_clean = test_df.dropna()\n",
        "\n",
        "# Separate features and target again\n",
        "X_test = test_df_clean[predictor_vars]\n",
        "y_test = test_df_clean[target_var]\n",
        "\n",
        "y_test_pred_lasso = lasso.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3 - Fill in the code below to get the R² and RMSE values.**"
      ],
      "metadata": {
        "id": "QTqpdV9nF71R"
      },
      "id": "QTqpdV9nF71R"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate R2 and RMSE\n",
        "r2 = ...(y_test, ...)\n",
        "rmse = sqrt(....(y_test, ...))\n",
        "print(f\"R2: {r2:.3f}, RMSE: {rmse:.3f}\")"
      ],
      "metadata": {
        "id": "MGgo2O_oF8G4"
      },
      "id": "MGgo2O_oF8G4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Solution\n",
        "# Calculate R2 and RMSE\n",
        "r2 = r2_score(y_test, y_test_pred_lasso)\n",
        "rmse = sqrt(mean_squared_error(y_test, y_test_pred_lasso))\n",
        "print(f\"R2: {r2:.3f}, RMSE: {rmse:.3f}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uwDXtt3W9dHw"
      },
      "id": "uwDXtt3W9dHw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can print out all the model coefficients to observe which penalties the Lasso model applied to each predictor.  \n",
        "This provides insight into which variables the model considered most important.  \n",
        "However, this information becomes more meaningful when compared to another model, so let's proceed by creating a Ridge regression model next."
      ],
      "metadata": {
        "id": "SbCzT2QVGD09"
      },
      "id": "SbCzT2QVGD09"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7a93271",
      "metadata": {
        "id": "e7a93271"
      },
      "outputs": [],
      "source": [
        "# View the parameters of the model\n",
        "print(\"Lasso coefficients:\")\n",
        "for feature, coef in zip(X.columns, lasso.coef_):\n",
        "    print(f\"{feature}: {coef:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Ridge` regression is a linear regression model that includes L2 regularization."
      ],
      "metadata": {
        "id": "yoxu_cS9GY3p"
      },
      "id": "yoxu_cS9GY3p"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge"
      ],
      "metadata": {
        "id": "6mwkYtJyGW9t"
      },
      "id": "6mwkYtJyGW9t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our datasets are already prepared, we can train a Ridge regression model directly without any additional setup."
      ],
      "metadata": {
        "id": "RoRygcXoGlEV"
      },
      "id": "RoRygcXoGlEV"
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a ridge regression model with initial alpha=1\n",
        "ridge = ...(alpha=1, max_iter=10000)\n",
        "ridge....(..., ...)"
      ],
      "metadata": {
        "id": "d2qqxvq0fDXT"
      },
      "id": "d2qqxvq0fDXT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Solution\n",
        "# Train a ridge regression model with initial alpha=1\n",
        "ridge = Ridge(alpha=1, max_iter=10000)\n",
        "ridge.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "sBFlbMm6utEZ",
        "cellView": "form"
      },
      "id": "sBFlbMm6utEZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets look at the metrics again, we will comapre them to the lasso matrics in goal 2!"
      ],
      "metadata": {
        "id": "FSHiCzj3Gx9w"
      },
      "id": "FSHiCzj3Gx9w"
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_ridge = ridge....(...)\n",
        "# Calculate R2 and RMSE\n",
        "r2 = r2_score(..., ...)\n",
        "rmse = sqrt(mean_squared_error(..., ...))\n",
        "print(f\"R2: {r2:.3f}, RMSE: {rmse:.3f}\")"
      ],
      "metadata": {
        "id": "2wDULGjUvLNH"
      },
      "id": "2wDULGjUvLNH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Solution\n",
        "y_test_pred_ridge = ridge.predict(X_test)\n",
        "# Calculate R2 and RMSE\n",
        "r2 = r2_score(y_test, y_test_pred_ridge)\n",
        "rmse = sqrt(mean_squared_error(y_test, y_test_pred_ridge))\n",
        "print(f\"R2: {r2:.3f}, RMSE: {rmse:.3f}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AzM2F2ogfzXI"
      },
      "id": "AzM2F2ogfzXI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that none of the coefficients are exactly zero.  \n",
        "This is a characteristic of Ridge regression, which will be discussed in more detail in the next objective."
      ],
      "metadata": {
        "id": "RBaBCGR4G5jZ"
      },
      "id": "RBaBCGR4G5jZ"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ridge coefficients:\")\n",
        "for feature, coef in zip(X.columns, ridge.coef_):\n",
        "    print(f\"{feature}: {coef:.4f}\")"
      ],
      "metadata": {
        "id": "GgRuwtV5vQuW"
      },
      "id": "GgRuwtV5vQuW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Goal 2: Comapre the models."
      ],
      "metadata": {
        "id": "qn7HMoKTjyYs"
      },
      "id": "qn7HMoKTjyYs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets first try to look at the preformance of both models.\n",
        "\n",
        "**Question 1 - Fill in the code below.**"
      ],
      "metadata": {
        "id": "enX2PWnLHn_d"
      },
      "id": "enX2PWnLHn_d"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Ridge\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(..., ..., alpha=0.6, color='royalblue')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.title(\"Ridge Regression\")\n",
        "\n",
        "# Lasso\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test, ..., alpha=0.6, color='darkorange')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.title(\"Lasso Regression\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W51uUL61kqx8"
      },
      "id": "W51uUL61kqx8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Solution\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Ridge\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_test, y_test_pred_ridge, alpha=0.6, color='royalblue')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.title(\"Ridge Regression\")\n",
        "\n",
        "# Lasso\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test, y_test_pred_lasso, alpha=0.6, color='darkorange')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.title(\"Lasso Regression\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AKYspzEOwtrE",
        "cellView": "form"
      },
      "id": "AKYspzEOwtrE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These type of graphs displays how closely the model's predictions align with the actual values.  \n",
        "A perfect model would have all points lying on the dashed line.  \n",
        "In this case, both models appear to perform similarly, so a closer examination is required to determine which model is superior.  \n",
        "However, it appears that the Lasso model may have a slight advantage, though additional evidence is needed to support this conclusion."
      ],
      "metadata": {
        "id": "0di-LxJ7j2JY"
      },
      "id": "0di-LxJ7j2JY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "One approach is to examine the coefficients of each model to glean insights about the relative importance of the predictors.\n",
        "\n",
        "**Question 2 - fill in the code below.**"
      ],
      "metadata": {
        "id": "7aOcsEnMI3dt"
      },
      "id": "7aOcsEnMI3dt"
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names =  ['NDVI', 'NBR', 'SAVI', 'MSAVI', 'DSI', 'NDWI', 'GLI', 'ND705', 'NDREI', 'IRECI', 'TGI', 'avg_95', 'avg', 'b10', 'b20', 'b30', 'b40', 'b50', 'b60', 'b70', 'b80', 'b90', 'dns_10m', 'dns_12m', 'dns_14m', 'dns_15m', 'dns_16m', 'dns_18m', 'dns_20m', 'dns_25m', 'dns_2m', 'dns_4m', 'dns_5m', 'dns_6m', 'dns_8m', 'kur_95', 'p01', 'p05', 'p10', 'p20', 'p30', 'p40', 'p50', 'p60', 'p70', 'p80', 'p90', 'p95', 'p99', 'qav', 'skew_95', 'd0_2', 'd10_12', 'd12_14', 'd14_16', 'd16_18', 'd18_20', 'd20_22', 'd22_24', 'd24_26', 'd26_28', 'd28_30', 'd2_4', 'd30_32', 'd32_34', 'd34_36', 'd36_38', 'd38_40', 'd40_42', 'd42_44', 'd44_46', 'd46_48', 'd4_6', 'd6_8', 'd8_10', 'std_95', 'vci_1mbin', 'vci_0.5bin']\n",
        "\n",
        "ridge_coef = ridge....\n",
        "lasso_coef = lasso....\n",
        "\n",
        "x = np.arange(len(feature_names))\n",
        "width = 0.35\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n",
        "\n",
        "# Plot 1\n",
        "# Use axes[0] for the first subplot\n",
        "axes[0].bar(x - width/2, ridge_coef, width, label='Ridge')\n",
        "axes[0].bar(x + width/2, lasso_coef, width, label='Lasso')\n",
        "axes[0].set_ylabel(\"Coefficient Value\")\n",
        "axes[0].set_title(\"Model Coefficient Comparison (All Features - Rotated Labels)\")\n",
        "axes[0].legend()\n",
        "\n",
        "\n",
        "# Prep data for top 20 coefs\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Ridge_Coef': ridge_coef,\n",
        "    'Lasso_Coef': lasso_coef\n",
        "})\n",
        "\n",
        "coef_df['Abs_Sum_Coef'] = np.abs(coef_df['Ridge_Coef']) + np.abs(coef_df['Lasso_Coef'])\n",
        "coef_df = coef_df.sort_values(by='Abs_Sum_Coef', ascending=False).head(25)\n",
        "\n",
        "top_feature_names = coef_df['Feature'].tolist()\n",
        "top_ridge_coef = coef_df['Ridge_Coef'].tolist()\n",
        "top_lasso_coef = coef_df['Lasso_Coef'].tolist()\n",
        "\n",
        "x_top = np.arange(len(top_feature_names))\n",
        "\n",
        "# Plot 2\n",
        "# Use axes[1] for the second subplot\n",
        "axes[1].barh(x_top - width/2, top_ridge_coef, width, label='Ridge')\n",
        "axes[1].barh(x_top + width/2, top_lasso_coef, width, label='Lasso')\n",
        "\n",
        "axes[1].set_xlabel(\"Coefficient Value\")\n",
        "axes[1].set_ylabel(\"Feature Name\")\n",
        "axes[1].set_title(\"Model Coefficient Comparison (Top 25 Features)\")\n",
        "axes[1].legend()\n",
        "axes[1].set_yticks(x_top)\n",
        "axes[1].set_yticklabels(top_feature_names, fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WYIEq9OIxZ1t"
      },
      "id": "WYIEq9OIxZ1t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Solution\n",
        "feature_names =  ['NDVI', 'NBR', 'SAVI', 'MSAVI', 'DSI', 'NDWI', 'GLI', 'ND705', 'NDREI', 'IRECI', 'TGI', 'avg_95', 'avg', 'b10', 'b20', 'b30', 'b40', 'b50', 'b60', 'b70', 'b80', 'b90', 'dns_10m', 'dns_12m', 'dns_14m', 'dns_15m', 'dns_16m', 'dns_18m', 'dns_20m', 'dns_25m', 'dns_2m', 'dns_4m', 'dns_5m', 'dns_6m', 'dns_8m', 'kur_95', 'p01', 'p05', 'p10', 'p20', 'p30', 'p40', 'p50', 'p60', 'p70', 'p80', 'p90', 'p95', 'p99', 'qav', 'skew_95', 'd0_2', 'd10_12', 'd12_14', 'd14_16', 'd16_18', 'd18_20', 'd20_22', 'd22_24', 'd24_26', 'd26_28', 'd28_30', 'd2_4', 'd30_32', 'd32_34', 'd34_36', 'd36_38', 'd38_40', 'd40_42', 'd42_44', 'd44_46', 'd46_48', 'd4_6', 'd6_8', 'd8_10', 'std_95', 'vci_1mbin', 'vci_0.5bin']\n",
        "\n",
        "ridge_coef = ridge.coef_\n",
        "lasso_coef = lasso.coef_\n",
        "\n",
        "x = np.arange(len(feature_names))\n",
        "width = 0.35\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n",
        "\n",
        "# Plot 1\n",
        "# Use axes[0] for the first subplot\n",
        "axes[0].bar(x - width/2, ridge_coef, width, label='Ridge')\n",
        "axes[0].bar(x + width/2, lasso_coef, width, label='Lasso')\n",
        "axes[0].set_ylabel(\"Coefficient Value\")\n",
        "axes[0].set_title(\"Model Coefficient Comparison (All Features - Rotated Labels)\")\n",
        "axes[0].legend()\n",
        "\n",
        "\n",
        "# Prep data for top 20 coefs\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Ridge_Coef': ridge_coef,\n",
        "    'Lasso_Coef': lasso_coef\n",
        "})\n",
        "\n",
        "coef_df['Abs_Sum_Coef'] = np.abs(coef_df['Ridge_Coef']) + np.abs(coef_df['Lasso_Coef'])\n",
        "coef_df = coef_df.sort_values(by='Abs_Sum_Coef', ascending=False).head(25)\n",
        "\n",
        "top_feature_names = coef_df['Feature'].tolist()\n",
        "top_ridge_coef = coef_df['Ridge_Coef'].tolist()\n",
        "top_lasso_coef = coef_df['Lasso_Coef'].tolist()\n",
        "\n",
        "x_top = np.arange(len(top_feature_names))\n",
        "\n",
        "# Plot 2\n",
        "# Use axes[1] for the second subplot\n",
        "axes[1].barh(x_top - width/2, top_ridge_coef, width, label='Ridge')\n",
        "axes[1].barh(x_top + width/2, top_lasso_coef, width, label='Lasso')\n",
        "\n",
        "axes[1].set_xlabel(\"Coefficient Value\")\n",
        "axes[1].set_ylabel(\"Feature Name\")\n",
        "axes[1].set_title(\"Model Coefficient Comparison (Top 20 Features)\")\n",
        "axes[1].legend()\n",
        "axes[1].set_yticks(x_top)\n",
        "axes[1].set_yticklabels(top_feature_names, fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2EpoxUsNooVh",
        "cellView": "form"
      },
      "id": "2EpoxUsNooVh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These types of graphs show the coefficients for each predictor and how each model penalized them.  \n",
        "An important concept to remember is that simpler models are generally preferred in machine learning, as they tend to avoid overfitting and perform better on real-world data.\n",
        "\n",
        "If Lasso eliminates many irrelevant variables, it results in a simpler model.  \n",
        "If this simplification leads to better performance compared to Ridge, it suggests that Lasso is the superior model overall.  \n",
        "However, we cannot draw this conclusion from the chart alone.  \n",
        "By examining the evaluation metrics from the final section of this goal, we can incorporate this information into our final decision."
      ],
      "metadata": {
        "id": "PA7jtgDBlrfA"
      },
      "id": "PA7jtgDBlrfA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, lets look at the RMSE (Root Mean Squared Error) and R² (Coefficient of Determination) values."
      ],
      "metadata": {
        "id": "LgnGLLaHKUDj"
      },
      "id": "LgnGLLaHKUDj"
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics(name, y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"{name} - RMSE: {rmse:.3f}, R²: {r2:.3f}\")\n",
        "\n",
        "print_metrics(\"Ridge\", y_test, y_test_pred_ridge)\n",
        "print_metrics(\"Lasso\", y_test, y_test_pred_lasso)"
      ],
      "metadata": {
        "id": "lyej8BCFyQsB"
      },
      "id": "lyej8BCFyQsB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RMSE (Root Mean Squared Error) is lower for the Lasso model, indicating that its predictions are, on average, closer to the actual values.\n",
        "\n",
        "The R² (Coefficient of Determination) is higher for Lasso, meaning it explains a greater proportion of the variance in the response variable (`biomass_Mg_ha`). Specifically, Lasso explains 46.5% of the variance, whereas Ridge explains only 26%.\n",
        "\n",
        "These results suggest that Lasso is the better model in this case, as it fits the data more accurately and generalizes more effectively."
      ],
      "metadata": {
        "id": "bLkOaUCTymA5"
      },
      "id": "bLkOaUCTymA5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3 - After our obervations, which model do you think is better to use for the final prediction?**"
      ],
      "metadata": {
        "id": "onntlDD9pwUy"
      },
      "id": "onntlDD9pwUy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer here*"
      ],
      "metadata": {
        "id": "ciaNVnI4kNzQ"
      },
      "id": "ciaNVnI4kNzQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details open>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "Based on our observations, the Lasso regression model appears to be the better choice for the final prediction. It achieves a lower RMSE, indicating more accurate predictions, and a higher R² value, meaning it explains a larger proportion of the variance in the target variable (`biomass_Mg_ha`). Additionally, Lasso's ability to perform variable selection and produce a simpler model reduces the risk of overfitting and improves generalizability. Therefore, Lasso is preferred over Ridge for this dataset.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "C9fHHZZMtZqf"
      },
      "id": "C9fHHZZMtZqf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Goal 3: Apply the best performing model for each response variable across the entire PRF"
      ],
      "metadata": {
        "id": "WMGvft2pd0Xr"
      },
      "id": "WMGvft2pd0Xr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use cross-validation to search for the optimal value of the regularization parameter alpha for our Lasso model. This process will help improve model performance by selecting the alpha that best balances bias and variance. We achieve this by evaluating multiple candidate alpha values and choosing the one that yields the best cross-validated score.\n"
      ],
      "metadata": {
        "id": "ojnTKZjXLsh6"
      },
      "id": "ojnTKZjXLsh6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **_NOTE:_**   This code might take some time to run, and disregard any warnings."
      ],
      "metadata": {
        "id": "9kXq2fayugKt"
      },
      "id": "9kXq2fayugKt"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "wetJ-_WQwp9H"
      },
      "id": "wetJ-_WQwp9H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_df = pd.concat([..., ...], axis=1)\n",
        "full_df_clean = test_df.dropna()\n",
        "\n",
        "# Separate features and target again\n",
        "X = full_df_clean[predictor_vars]\n",
        "y = full_df_clean[target_var]\n",
        "\n",
        "\n",
        "alphas = np.logspace(-3, 3, 300)\n",
        "lasso_cv = ...(Lasso(max_iter=10000), param_grid={'alpha': alphas}, scoring='neg_mean_squared_error', cv=5)\n",
        "lasso_cv.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "c23k_U78oTSA"
      },
      "id": "c23k_U78oTSA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Solution\n",
        "alphas = np.logspace(-3, 3, 300)\n",
        "lasso_cv = GridSearchCV(Lasso(max_iter=10000), param_grid={'alpha': alphas}, scoring='neg_mean_squared_error', cv=5)\n",
        "lasso_cv.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "AlyEC7U1wEOJ",
        "collapsed": true,
        "cellView": "form"
      },
      "id": "AlyEC7U1wEOJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_opt = Lasso(alpha=lasso_cv.best_params_['alpha'], max_iter=10000)\n",
        "lasso_opt.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "rRwP_vCaC3wF"
      },
      "id": "rRwP_vCaC3wF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets make our final prediction!"
      ],
      "metadata": {
        "id": "l__pZt8GL2Gj"
      },
      "id": "l__pZt8GL2Gj"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_full = lasso_opt.predict(X_test)"
      ],
      "metadata": {
        "id": "nByYLDKOL1lM"
      },
      "id": "nByYLDKOL1lM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a few ways we can visulize our results. Lets go through them!"
      ],
      "metadata": {
        "id": "0T9OFClVL6iQ"
      },
      "id": "0T9OFClVL6iQ"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "sns.scatterplot(x=y_test, y=y_pred_full, alpha=0.6)\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], color='red', linestyle='--', label='Perfect Prediction Line') # y=x line\n",
        "plt.title('Actual vs. Predicted Biomass')\n",
        "plt.xlabel('Actual Biomass (Mg/ha)')\n",
        "plt.ylabel('Predicted Biomass (Mg/ha)')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tGgqL36Fpq6c"
      },
      "id": "tGgqL36Fpq6c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like how we seen before, an Actual vs Predicted graph is always good to see at a quick glance how our model preformed. Below lets print out the metrics to compare this final model quantitatively."
      ],
      "metadata": {
        "id": "CSnIcpijMBK-"
      },
      "id": "CSnIcpijMBK-"
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics(\"Lasso CV\", y_test, y_pred_full)"
      ],
      "metadata": {
        "id": "YJFKyvIWsTCf"
      },
      "id": "YJFKyvIWsTCf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1 - Given that our model now achieves a higher R² and a lower RMSE compared to previous trial sets, does this indicate that the model’s performance has improved or deteriorated?**\n"
      ],
      "metadata": {
        "id": "fkz7ht8ZMOCg"
      },
      "id": "fkz7ht8ZMOCg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer here*"
      ],
      "metadata": {
        "id": "myqxiAxQk0bN"
      },
      "id": "myqxiAxQk0bN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details open>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "While there is improvment in having a higher R² and lower RMSE, it is marginal. However any improvment is welcomed and thus our model has imporved!\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "IaoLm7UOIuga"
      },
      "id": "IaoLm7UOIuga"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets create a redisdual plot. To do this, you must calculate the difference between the predicted `y_pred_full` from the actual `y_test` values.\n",
        "\n",
        "**Question 2 - fill in the code below.**"
      ],
      "metadata": {
        "id": "LyHNCpZ-DQbz"
      },
      "id": "LyHNCpZ-DQbz"
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = ... - ...\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=y_pred_full, y=residuals, alpha=0.6)\n",
        "plt.axhline(y=0, color='red', linestyle='--', label='Zero Residual Line') # Zero error line\n",
        "plt.title('Residuals Plot (Predicted vs. Residuals)')\n",
        "plt.xlabel('Predicted Biomass (Mg/ha)')\n",
        "plt.ylabel('Residuals (Actual - Predicted)')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kv7VcEbVFu7e"
      },
      "id": "Kv7VcEbVFu7e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Solution\n",
        "residuals = y_test - y_pred_full\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=y_pred_full, y=residuals, alpha=0.6)\n",
        "plt.axhline(y=0, color='red', linestyle='--', label='Zero Residual Line') # Zero error line\n",
        "plt.title('Residuals Plot (Predicted vs. Residuals)')\n",
        "plt.xlabel('Predicted Biomass (Mg/ha)')\n",
        "plt.ylabel('Residuals (Actual - Predicted)')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eM3uM-aNr01E",
        "cellView": "form"
      },
      "id": "eM3uM-aNr01E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A residual plot is useful for detecting any patterns or trends in the residuals.  \n",
        "We do **not** want to observe any trends, as their presence can indicate multicollinearity among variables, which is undesirable.  \n",
        "Ideally, the residuals should be randomly and evenly dispersed, as demonstrated once the plot above is generated.\n",
        "\n",
        "Now run the code below to see the final sets of graphs."
      ],
      "metadata": {
        "id": "A6o0a3v5Mind"
      },
      "id": "A6o0a3v5Mind"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up side-by-side subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Histogram with KDE\n",
        "sns.histplot(residuals, kde=True, ax=axes[0])\n",
        "axes[0].set_title('Distribution of Residuals')\n",
        "axes[0].set_xlabel('Residuals')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Q-Q plot\n",
        "sm.qqplot(residuals, line='s', ax=axes[1])\n",
        "axes[1].set_title('Q-Q Plot of Residuals')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vXLohSJJr9dg"
      },
      "id": "vXLohSJJr9dg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the histogram below, the residuals should ideally form a bell-shaped distribution (approximately normal) centered around zero.  \n",
        "\n",
        "Regarding the Q-Q plot, if the points largely follow the straight reference line, it suggests that the residuals are approximately normally distributed.  \n",
        "Deviations from this line indicate departures from normality. Both of these graphs can help determine that out experiment falls into line what should be expected of a good result."
      ],
      "metadata": {
        "id": "IRDDKjz4M67J"
      },
      "id": "IRDDKjz4M67J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To summarize, we now have our final model, and we have confirmed that the results align with what we expect from a well-performing model based on the residual trends. Lasso regression was chosen for this dataset due to its superior performance in this case. However, this does not imply that Ridge regression is an inferior model; depending on the dataset, Ridge may perform better. Therefore, it is always advisable to test multiple regression methods for any analysis.\n",
        "\n",
        "Furthermore, if new data similar to this set becomes available, we can use our final model to predict the overall `biomass_Mg_ha`. This encapsulates the main objective of our work here.\n"
      ],
      "metadata": {
        "id": "QYLcg2ptxI8z"
      },
      "id": "QYLcg2ptxI8z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References"
      ],
      "metadata": {
        "id": "WH75aYyikd7t"
      },
      "id": "WH75aYyikd7t"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini. (2025). Assistance is editing writeups and code. Retrieved from https://gemini.google.com"
      ],
      "metadata": {
        "id": "RrnX-9uukgdv"
      },
      "id": "RrnX-9uukgdv"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}